#!/bin/bash

subj_id=SUBJECTID
ses_id=SESID
data_dir=DATADIR
data_bucket=BUCKET
run_dir=RUNDIR
singularity=`which singularity`

BIDS_DIR=${data_dir}/sub-${subj_id}
OUTPUT_DIR=${data_dir}/processed/dcan-infant-pipeline-beginning

# pull down needed data and files from BIDS bucket
if [ ! -d ${data_dir}/sub-${subj_id}/ses-${ses_id} ]; then
	mkdir -p ${BIDS_DIR}
	s3cmd get ${data_bucket}/sub-${subj_id}/ses-${ses_id} ${BIDS_DIR} --recursive -v
fi
if [ ! -e ${data_dir}/dataset_description.json ]; then
	cp ${run_dir}/dataset_description.json ${data_dir} -v
fi
if [ ! -e ${data_dir}/participants.tsv ]; then
	s3cmd get ${data_bucket}/participants.tsv ${data_dir} -v 
fi

# create processed and derivatives folders if they do not exist
if [ ! -d ${data_dir}/processed/dcan-infant-pipeline-beginning ]; then
	mkdir ${data_dir}/processed/
	mkdir ${data_dir}/processed/dcan-infant-pipeline-beginning/
fi

env -i ${singularity} run --cleanenv \
-B ${run_dir}/license.txt:/opt/freesurfer/license.txt \
-B ${data_dir}:/bids_input:ro \
-B ${OUTPUT_DIR}:/output \
/home/faird/shared/code/internal/pipelines/DCAN-infant-BIDS/infant-abcd-bids-pipeline_v0.0.22.sif \
/bids_input /output \
--freesurfer-license /opt/freesurfer/license.txt \
--ncpus 8 --stages="PreFreeSurfer:FreeSurfer" --participant-label ${subj_id} --session-id ${ses_id} --atropos-mask-method CREATE --jlf-method T2W

#push processed outputs to bucket
s3cmd sync -F --recursive -v --delete-removed ${OUTPUT_DIR}/sub-${subj_id}/ses-${ses_id}/ s3://WashU_data_sharing/eLABE/dcaninfant-processed/dcan-infant-pipeline-beginning/sub-${subj_id}/ses-${ses_id}/

# run filemapper
