#!/bin/bash 

sub_id=SUBJECTID
ses_id=SESID
data_dir=DATADIR
bucket_name=BUCKET
run_folder=RUNDIR


#sync BIDS inputs
if [ ! -d ${data_dir}/sub-${sub_id}/ses-${ses_id} ]; then
	mkdir -p ${data_dir}/sub-${sub_id}
	s3cmd get ${bucket_name}/sub-${sub_id}/ses-${ses_id} ${data_dir}/sub-${sub_id}/ --recursive -v
fi
if [ ! -e ${data_dir}/dataset_description.json ]; then
	cp ${run_folder}/dataset_description.json ${data_dir}/
fi
if [ ! -e ${data_dir}/participants.tsv ]; then
	cp ${run_folder}/participants.tsv ${data_dir}/
fi

#run intendedfor script
source /home/faird/shared/code/external/envs/miniconda3/load_miniconda3.sh
#conda activate abcd-dicom2bids
#module load python
#python /home/faird/shared/code/internal/utilities/intended-fors/intended_for.py ${data_dir}/ closest
python /home/feczk001/shared/projects/cabinet_paper_results/intendedfors_on_s3_wrapper/IntendedFor.py --ses ${data_dir}/sub-${sub_id}/ses-${ses_id}/
#resync to bucket on s3
s3cmd sync -F --recursive -v ${data_dir}/sub-${sub_id}/ses-${ses_id}/ ${bucket_name}/sub-${sub_id}/ses-${ses_id}/
#remove processed inputs and derivatives
rm -r ${data_dir}
