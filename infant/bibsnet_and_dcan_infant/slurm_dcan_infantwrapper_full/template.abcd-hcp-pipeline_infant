#!/bin/bash

subj_id=SUBJECTID
ses_id=SESID
data_dir=DATADIR
data_bucket=BUCKET
run_dir=RUNDIR

module load singularity; \
singularity=`which singularity`

BIDS_DIR=${data_dir}/sub-${subj_id}
OUTPUT_DIR=${data_dir}/processed/dcan-infant-pipeline-full
ASEG_DIR=${data_dir}/aseg_dir_${subj_id}

# pull down needed data and files from BIDS bucket
if [ ! -d ${data_dir}/sub-${subj_id}/ses-${ses_id} ]; then
	mkdir -p ${BIDS_DIR}
	s3cmd get ${data_bucket}/sub-${subj_id}/ses-${ses_id} ${BIDS_DIR} --recursive -v
fi
if [ ! -d ${data_dir}/aseg_dir_${subj_id}/ ]; then
	mkdir -p ${ASEG_DIR}
	s3cmd get s3://WashU_data_sharing/eLABE/dcaninfant-processed/dcan-infant-pipeline-segmentation-model515/sub-${subj_id}/ses-${ses_id}/sub-${subj_id}_ses-${ses_id}_aseg_cc.nii.gz ${ASEG_DIR} -v
fi
if [ ! -e ${data_dir}/dataset_description.json ]; then
	cp ${run_dir}/dataset_description.json ${data_dir}
fi
if [ ! -e ${data_dir}/participants.tsv ]; then
	s3cmd get ${data_bucket}/participants.tsv ${data_dir} -v 
fi

# create processed and derivatives folders if they do not exist
if [ ! -d ${data_dir}/processed/dcan-infant-pipeline-full ]; then
	mkdir ${data_dir}/processed/
	mkdir ${data_dir}/processed/dcan-infant-pipeline-full/
	mkdir ${data_dir}/processed/dcan-infant-pipeline-full/sub-${subj_id}/
	mkdir ${data_dir}/processed/dcan-infant-pipeline-full/sub-${subj_id}/ses-${ses_id}/
	s3cmd get s3://WashU_data_sharing/eLABE/dcaninfant-processed/dcan-infant-pipeline-beginning/sub-${subj_id}/ses-${ses_id}/ ${data_dir}/processed/dcan-infant-pipeline-full/sub-${subj_id}/ses-${ses_id}/ --recursive -v
	s3cmd get s3://WashU_data_sharing/eLABE/dcaninfant-processed/dcan-infant-pipeline-segmentation-model515/sub-${subj_id}/ses-${ses_id}/sub-${subj_id}_ses-${ses_id}_T2w_acpc_dc_restore_brain_mask.nii.gz ${data_dir}/processed/dcan-infant-pipeline-full/sub-${subj_id}/ses-${ses_id}/ -v
	mv ${data_dir}/processed/dcan-infant-pipeline-full/sub-${subj_id}/ses-${ses_id}/sub-${subj_id}_ses-${ses_id}_T2w_acpc_dc_restore_brain_mask.nii.gz ${data_dir}/processed/dcan-infant-pipeline-full/sub-${subj_id}/ses-${ses_id}/files/T1w/T2w_acpc_dc_restore_brain_mask.nii.gz -v
fi


env -i ${singularity} run --cleanenv \
-B ${run_dir}/license.txt:/opt/freesurfer/license.txt \
-B ${data_dir}:/bids_input:ro \
-B ${OUTPUT_DIR}:/output \
-B ${ASEG_DIR}:/aseg \
/home/faird/shared/code/internal/pipelines/DCAN-infant-BIDS/infant-abcd-bids-pipeline_latest_02202023a.sif \
/bids_input /output --freesurfer-license /opt/freesurfer/license.txt \
--stages="FreeSurfer:ExecutiveSummary" \
--ncpus 13 --participant-label ${subj_id} --session-id ${ses_id} --aseg /aseg/sub-${subj_id}_ses-${ses_id}_aseg_cc.nii.gz --atropos-mask-method NONE --hyper-normalization-method ROI_IPS


#push processed outputs to bucket
s3cmd sync -F --recursive -v --delete-removed ${OUTPUT_DIR}/sub-${subj_id}/ses-${ses_id}/ s3://WashU_data_sharing/eLABE/dcaninfant-processed/dcan-infant-pipeline-full-model515-t2only/sub-${subj_id}/ses-${ses_id}/

# run filemapper
